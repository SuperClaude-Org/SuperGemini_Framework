# SuperGemini User Guide üöÄ

## üéØ The Simple Truth

**Behind the apparent complexity, SuperGemini is actually simple to use.**

You don't need to learn all the commands, flags, and personas. Just start using it! üéà

SuperGemini has an **intelligent routing system** that tries to figure out what you need:
- Type `/analyze some-code/` ‚Üí It picks the right analysis tools
- Ask about security ‚Üí Security expert auto-activates  
- Work on frontend ‚Üí UI specialist takes over
- Debug something ‚Üí Investigation mode kicks in

**Learning emerges during use** - you'll naturally discover what works without studying manuals first.

The detailed guides below? They're here **when you want to understand** what just happened or dive deeper. But honestly? Most of the time you can just wing it. üòä

---

**TL;DR**: Install it, try `/analyze` or `/build` on your code, watch the magic happen.

---

A comprehensive guide to understanding and using SuperGemini v3.0 effectively. But remember - you can skip straight to trying it out!

## Table of Contents üìñ

1. [Welcome & Overview](#welcome--overview-)
2. [Core Components](#core-components-)
3. [The Three Operational Modes](#the-three-operational-modes-)
4. [The Orchestrator System](#the-orchestrator-system-)
5. [Rules & Principles](#rules--principles-)
6. [Getting Started Workflows](#getting-started-workflows-)
7. [Integration & Coordination](#integration--coordination-)
8. [Practical Examples](#practical-examples-)
9. [Tips & Best Practices](#tips--best-practices-)
10. [Troubleshooting](#troubleshooting--common-issues-)
11. [What's Next](#whats-next-)

---

## üöÄ Just Start Here

**Want to skip the reading and jump right in?** Here's your 2-minute getting started:

```bash
# Try these commands in Gemini Code:
/sg:help                    # See what's available
/sg:analyze README.md       # SuperGemini analyzes your project
/sg:workflow feature-prd.md # Generate implementation workflow from PRD (NEW!)
/sg:implement user-auth     # Create features and components (NEW in v3!)
/sg:build                   # Smart build with auto-optimization  
/sg:improve messy-file.js   # Clean up code automatically
```

**What just happened?** SuperGemini automatically:
- Picked the right tools for each task üõ†Ô∏è
- Activated appropriate experts (security, performance, etc.) üé≠  
- Applied intelligent flags and optimizations ‚ö°
- Provided evidence-based suggestions üìä

**See how easy that was?** No studying required - SuperGemini figures out the complexity so you don't have to.

Want to understand how it works? Keep reading. Want to just keep experimenting? Go for it! üéØ

---

## Welcome & Overview üëã

### What is SuperGemini Really? ü§î

SuperGemini makes Gemini Code smarter for development work. Instead of generic responses, you get specialized help from different experts (security, performance, frontend, etc.) who know their stuff.

**The honest truth**: We just released v3.0 and it's fresh out of beta. It works pretty well for what it does, but you should expect some rough edges as we continue improving things. We built this because we wanted Gemini Code to be more helpful for real software development workflows.

**The neat part?** You don't need to manage any of this complexity. Just use normal commands like `/analyze` or `/build` and SuperGemini usually figures out which experts to involve and what tools to use. ü™Ñ

### What SuperGemini Adds ‚ú®

**üõ†Ô∏è 17 Specialized Commands**
- Planning tools: `/workflow` (NEW!), `/estimate`, `/task`
- Development tools: `/implement`, `/build`, `/design`
- Analysis tools: `/analyze`, `/troubleshoot`, `/explain` 
- Quality tools: `/improve`, `/cleanup`, `/test`
- Plus utilities for documentation, git, deployment, and more
- **You just use them** - SuperGemini handles the complexity automatically
- **NEW**: `/workflow` command for PRD-to-implementation planning
- **NEW**: `/implement` command for feature creation (restores v2 functionality) 

**üé≠ 11 Smart Personas** *(that know when to jump in)*
- AI specialists that adapt behavior for different domains
- **Auto-activate based on your requests** (security expert for security tasks, etc.)
- Manual control available, but usually not needed
- Think of it as having a whole dev team that knows when to help

**üîß MCP Server Integration** *(smart external tools)*
- Context7: Official library documentation lookup
- Sequential: Complex multi-step analysis
- Magic: Modern UI component generation
- Playwright: Browser automation and testing
- **Auto-connects when needed** - you don't manage this stuff

**üìã Enhanced Task Management** *(happens behind the scenes)*
- Progress tracking with TodoRead/TodoWrite
- Multi-session project management with `/task`
- Complex orchestration with `/spawn`
- Iterative improvement with `/loop`
- **Mostly automatic** - SuperGemini tracks what you're doing

**‚ö° Token Optimization** *(smart efficiency)*
- Smart compression when context gets full
- Symbol system for efficient communication
- Performance optimization for large operations
- **Usually activates** when needed for large projects

### Current Status (v3.0) üìä

**‚úÖ What's Working Well:**
- Installation system (completely rewritten, much more reliable)
- Core framework with 16 commands and 11 personas
- MCP server integration (mostly working)
- Basic task management and workflow automation
- Documentation and user guides

**‚ö†Ô∏è What's Still Rough:**
- This is an initial release - bugs are expected
- Some MCP integrations could be smoother
- Performance isn't optimized yet for all operations
- Some advanced features are experimental

**‚ùå What We Removed:**
- Hooks system (got too complex, coming back in v4)

We're pretty happy with v3 as a foundation, but there's definitely room for improvement.

### How It Works üîÑ

**The simple version**: You type something like `/analyze auth.js` and SuperGemini figures out the rest.

**The slightly more detailed version**:

1. **Smart routing** - Analyzes what you're asking for
2. **Auto-expert selection** - Picks the right specialist (security, performance, etc.)
3. **Tool coordination** - Connects to external systems when helpful
4. **Quality assurance** - Makes sure suggestions are solid

**You don't see any of this complexity** - it just feels like Gemini got way smarter about development stuff. 

The nice thing is that most of this usually happens automatically. You make a request, SuperGemini tries to figure out a good approach, and executes with appropriate tools and expertise. Usually no configuration or setup needed - just hopefully better results. ‚ú®

### Quick Feature Overview üéØ

| Component | What It Does | Learn More *(optional!)* |
|-----------|--------------|------------|
| **Commands** | 15 specialized tools that auto-activate | [Commands Guide](commands-guide.md) |
| **Flags** | Modifiers that mostly activate automatically | [Flags Guide](flags-guide.md) |
| **Personas** | 11 AI specialists that know when to help | [Personas Guide](personas-guide.md) |
| **MCP Servers** | External integrations that connect when useful | [This guide](#core-components-üß©) |
| **Modes** | 3 operational modes for different workflows | [This guide](#the-three-operational-modes-üé≠) |
| **Orchestrator** | The smart routing that makes it all work | [This guide](#the-orchestrator-system-üéØ) |

**Remember**: You can use SuperGemini effectively without reading any of these guides. They're here when you get curious about how it works! üé™

---

## Core Components üß©

SuperGemini is built from several interconnected systems that work together. Here's how each component fits into the bigger picture.

### Commands: Your Toolkit üõ†Ô∏è

Commands are specialized tools that handle specific types of development work. Instead of generic "help me with this," you get purpose-built tools for different scenarios.

**15 Commands Organized by Purpose:**

**Development** üî®
- `/build` - Project building, compilation, bundling
- `/design` - System architecture and component design

**Analysis** üîç  
- `/analyze` - Comprehensive code and system analysis
- `/troubleshoot` - Problem investigation and debugging
- `/explain` - Educational explanations and learning

**Quality** ‚ú®
- `/improve` - Code enhancement and optimization
- `/cleanup` - Technical debt reduction
- `/test` - Testing and coverage analysis

**Utilities** üîß
- `/document` - Documentation creation
- `/git` - Enhanced git workflows
- `/load` - Project context loading
- `/estimate` - Project estimation
- `/task` - Long-term project management
- `/spawn` - Complex operation orchestration
- `/index` - Command navigation and help

Each command has its own flags, auto-activates appropriate personas, and integrates with relevant MCP servers. For detailed examples and usage patterns, see the [Commands Guide](commands-guide.md).

### Flags: Behavior Modifiers üèÅ

Flags change how SuperGemini processes your requests. They're like command-line options that modify behavior, add capabilities, or change output style.

**Key Flag Categories:**

**Planning & Analysis** üß†
- `--seq` - Enable systematic analysis for complex problems
- `--plan` - Show execution plan before running

**Efficiency & Control** ‚ö°
- `--uc` - Ultra-compressed output for large operations
- `--safe-mode` - Conservative execution with validation
- `--validate` - Pre-operation risk assessment

**MCP Server Control** üîß
- `--c7` - Enable Context7 for documentation
- `--seq` - Enable Sequential for complex analysis
- `--magic` - Enable Magic for UI components
- `--play` - Enable Playwright for testing

**Advanced Orchestration** üé≠
- `--wave-mode` - Multi-stage execution with compound intelligence
- `--loop` - Iterative improvement mode

**Focus & Scope** üéØ
- `--focus security` - Focus on specific domains
- `--scope project` - Set analysis scope
- `--persona-[name]` - Activate specific personas

Flags often auto-activate based on context. For example, security-related requests usually get `--persona-security` and `--focus security`. See the [Flags Guide](flags-guide.md) for comprehensive details and patterns.

### Personas: AI Specialists üé≠

Personas are like having a team of specialists available on demand. Each brings different expertise, priorities, and approaches to problems.

**11 Personas Organized by Domain:**

**Technical Specialists** üîß
- üèóÔ∏è **architect** - Systems design, long-term architecture
- üé® **frontend** - UI/UX, accessibility, frontend performance
- ‚öôÔ∏è **backend** - APIs, databases, reliability
- üõ°Ô∏è **security** - Threat modeling, vulnerabilities
- ‚ö° **performance** - Optimization, bottleneck elimination

**Process & Quality** ‚ú®
- üîç **analyzer** - Root cause analysis, investigation
- üß™ **qa** - Testing, quality assurance
- üîÑ **refactorer** - Code quality, technical debt
- üöÄ **devops** - Infrastructure, deployment

**Knowledge & Communication** üìö
- üë®‚Äçüè´ **mentor** - Education, knowledge transfer
- ‚úçÔ∏è **scribe** - Documentation, technical writing

Personas usually auto-activate based on request patterns but you can override with `--persona-[name]` flags. Each has different priorities (e.g., security persona prioritizes security over speed). See the [Personas Guide](personas-guide.md) for detailed descriptions and examples.

### MCP Servers: External Capabilities üîß

MCP (Model Context Protocol) servers provide specialized capabilities beyond Gemini's native abilities.

**4 Integrated Servers:**

**Context7** üìö
- **Purpose**: Official library documentation and best practices
- **When it activates**: Framework questions, external library usage
- **What it provides**: Up-to-date docs, code examples, patterns
- **Example**: `/build react-app --c7` gets React best practices

**Sequential** üß†
- **Purpose**: Complex multi-step analysis and systematic thinking
- **When it activates**: Debugging, system design, `--seq` flags
- **What it provides**: Structured problem-solving, hypothesis testing
- **Example**: `/troubleshoot "auth randomly fails" --seq`

**Magic** ‚ú®
- **Purpose**: Modern UI component generation and design systems
- **When it activates**: UI component requests, frontend work
- **What it provides**: React/Vue/Angular components, design patterns
- **Example**: `/build dashboard --magic` creates modern UI components

**Playwright** üé≠
- **Purpose**: Browser automation, E2E testing, performance monitoring
- **When it activates**: Testing workflows, performance analysis
- **What it provides**: Cross-browser testing, visual validation, metrics
- **Example**: `/test e2e --play` runs comprehensive browser tests

MCP servers usually coordinate automatically but you can control them with `--all-mcp`, `--no-mcp`, or specific flags like `--c7`.

### How Components Work Together ü§ù

The neat part is when components coordinate:

**Example: Security Analysis Request**
```bash
/sg:analyze auth-system/ --focus security
```

**What usually happens:**
1. **Command**: `/analyze` handles code analysis
2. **Flag**: `--focus security` directs attention
3. **Persona**: üõ°Ô∏è security specialist auto-activates
4. **MCP**: Sequential provides systematic analysis
5. **Orchestrator**: Routes everything for optimal execution

**Result**: Security-focused analysis with threat modeling perspective, systematic methodology, and comprehensive coverage.

This coordination usually happens for most requests - SuperGemini tries to figure out a good combination of tools and expertise for your specific need.

---

## The Three Operational Modes üé≠

SuperGemini operates in three distinct modes that optimize different aspects of the development workflow. Understanding these modes helps you get the most out of the framework.

### Task Management Mode üìã

**What it is**: Structured workflow execution with progress tracking and validation.

**When it's used**: Any multi-step operation that needs tracking and coordination.

**How it works**: SuperGemini breaks work into manageable tasks, tracks progress, and ensures quality through validation gates.

#### Four Layers of Task Management

**Layer 1: Session Tasks (TodoRead/TodoWrite)**
- **Scope**: Current Gemini Code session
- **Capacity**: 3-20 tasks per session
- **States**: pending üìã, in_progress üîÑ, completed ‚úÖ, blocked üöß
- **Usage**: Real-time progress tracking for immediate work

```bash
# SuperGemini usually creates and manages session tasks
/sg:build large-project/
# ‚Üí Creates: "Analyze project structure", "Run build process", "Validate output"
```

**Layer 2: Project Tasks (/task command)**
- **Scope**: Multi-session features (days to weeks)
- **Structure**: Hierarchical (Epic ‚Üí Story ‚Üí Task)
- **Persistence**: Cross-session state management
- **Usage**: Long-term feature development

```bash
/sg:task create "implement user dashboard" --priority high
/sg:task breakdown "payment integration"
/sg:task status  # Check current project tasks
```

**Layer 3: Wave Orchestration**
- **Scope**: Complex multi-domain operations
- **Features**: Multi-stage execution with progressive enhancement
- **Usage**: System-wide improvements, comprehensive analysis

```bash
/sg:analyze system/ --wave-mode force --wave-strategy systematic
/sg:improve legacy-code/ --wave-mode auto
```

**Layer 4: Iterative Enhancement (/loop command)**
- **Scope**: Progressive refinement workflows
- **Features**: Iteration cycles with validation
- **Usage**: Quality improvement and refinement

```bash
/sg:improve messy-code.js --loop --iterations 3
# ‚Üí Iteratively improves code with validation between cycles
```

#### Task State Management

**Core Principles**:
- **Evidence-Based Progress**: Measurable outcomes, not just activity
- **Single Focus Protocol**: Only one task in_progress at a time
- **Real-Time Updates**: Immediate status changes as work progresses
- **Quality Gates**: Validation before marking tasks complete

**Task Detection**:
- Multi-step operations (3+ steps) ‚Üí Creates task breakdown
- Keywords: build, implement, create, fix, optimize ‚Üí Activates task tracking
- Scope indicators: system, feature, comprehensive ‚Üí Adds progress monitoring

### Introspection Mode üß†

**What it is**: Meta-cognitive analysis that lets SuperGemini examine its own reasoning and decision-making processes.

**When it's used**: Complex problem-solving, framework troubleshooting, learning moments, or when you explicitly request it with `--introspect`.

**How it works**: SuperGemini steps outside normal operation to analyze its thinking patterns, decision logic, and action sequences.

#### Core Capabilities

**Reasoning Analysis** üß†
- Examines logical flow and decision rationale
- Evaluates chain of thought coherence
- Identifies assumptions and potential biases
- Validates reasoning against evidence

**Action Sequence Review** üîÑ
- Analyzes tool selection effectiveness
- Reviews workflow patterns and efficiency
- Considers alternative approaches
- Identifies optimization opportunities

**Framework Compliance Check** üîç
- Validates actions against SuperGemini rules and principles
- Identifies deviations from standard patterns
- Provides corrective guidance when needed
- Ensures quality standards are met

**Learning Recognition** üí°
- Extracts insights from outcomes
- Identifies successful patterns for reuse
- Recognizes knowledge gaps for improvement
- Suggests future optimization strategies

#### Analysis Markers

When introspection mode is active, you'll see these markers:

- üß† **Reasoning Analysis** - Examining logical flow and decisions
- üîÑ **Action Sequence Review** - Analyzing workflow effectiveness
- üéØ **Self-Assessment** - Meta-cognitive evaluation
- üìä **Pattern Recognition** - Identifying behavioral patterns
- üîç **Framework Compliance** - Checking rule adherence
- üí° **Retrospective Insight** - Learning from outcomes

#### When Introspection Activates

**Usually activates for**:
- Complex multi-step problems requiring meta-cognitive oversight
- Error recovery when outcomes don't match expectations
- Framework discussions or SuperGemini troubleshooting
- Pattern recognition needs for recurring behaviors

**Manual activation**:
```bash
/sg:analyze complex-system/ --introspect
/sg:troubleshoot "framework confusion" --introspection
```

### Token Efficiency Mode ‚ö°

**What it is**: Intelligent optimization system that maximizes information density while preserving quality.

**When it's used**: Large operations, when context approaches limits, or when you need faster execution.

**How it works**: Adaptive compression using symbols, abbreviations, and structural optimization based on context and persona awareness.

#### Compression Strategies

**5-Level Adaptive Compression**:
1. **Minimal** (0-40% usage): Full detail with persona-optimized clarity
2. **Efficient** (40-70% usage): Balanced compression with domain awareness  
3. **Compressed** (70-85% usage): Aggressive optimization with quality gates
4. **Critical** (85-95% usage): Maximum compression preserving essential context
5. **Emergency** (95%+ usage): Ultra-compression with information validation

#### Symbol System

**Core Logic & Flow**:
- `‚Üí` leads to, implies (`auth.js:45 ‚Üí security risk`)
- `‚áí` transforms to (`input ‚áí validated_output`)
- `&` and, combine (`security & performance`)
- `¬ª` sequence, then (`build ¬ª test ¬ª deploy`)
- `‚à¥` therefore (`tests fail ‚à¥ code broken`)

**Status & Progress**:
- ‚úÖ completed, passed
- ‚ùå failed, error  
- ‚ö†Ô∏è warning
- üîÑ in progress
- üéØ target, goal

**Technical Domains**:
- ‚ö° Performance
- üîç Analysis
- üõ°Ô∏è Security
- üì¶ Deployment
- üé® Design

#### Activation Strategy

**Usually activates when**:
- Context usage >75% ‚Üí Enables compression
- Large-scale operations ‚Üí Prevents token overflow
- Complex orchestration ‚Üí Optimizes communication

**Manual activation**:
```bash
/sg:analyze huge-codebase/ --uc  # Ultra-compressed mode
/sg:improve legacy-system/ --uc --wave-mode auto  # Efficient large operations
```

**Performance Goals** (still improving!):
- Target: ~30-50% token reduction
- Quality: Tries to preserve ~95% of information
- Speed: Usually <100ms compression decisions
- Integration: Works with framework components

#### Mode Integration

The three modes often work together:

```bash
/sg:improve large-legacy-system/ --wave-mode auto --uc --introspect
```

**What happens**:
- **Task Management**: Creates structured improvement plan with progress tracking
- **Token Efficiency**: Compresses output for large-scale operation
- **Introspection**: Analyzes improvement strategy and validates approach

---

## The Orchestrator System üéØ

The orchestrator is SuperGemini's intelligent routing system that tries to analyze your requests and coordinate a good combination of tools, personas, and integrations. It's what hopefully makes SuperGemini feel smart and responsive rather than just a collection of separate tools.

### How the Orchestrator Works üîÑ

**Think of it as a smart dispatcher** that:
1. **Analyzes** your request to understand intent and complexity
2. **Routes** to the best combination of commands, flags, personas, and MCP servers
3. **Coordinates** execution for optimal results
4. **Validates** through quality gates to ensure good outcomes
5. **Optimizes** performance and resource usage

### Detection Engine üß†

The detection engine analyzes every request through multiple lenses:

#### Pattern Recognition

**Complexity Detection**:
- **Simple**: Single file operations, basic tasks (<3 steps) ‚Üí Direct execution
- **Moderate**: Multi-file operations, analysis tasks (3-10 steps) ‚Üí Standard routing
- **Complex**: System-wide changes, architectural decisions (>10 steps) ‚Üí Advanced orchestration

**Domain Identification**:
- **Frontend**: Keywords like "UI", "component", "responsive" ‚Üí üé® frontend persona + Magic MCP
- **Backend**: Keywords like "API", "database", "service" ‚Üí ‚öôÔ∏è backend persona + Context7 MCP
- **Security**: Keywords like "vulnerability", "auth", "compliance" ‚Üí üõ°Ô∏è security persona + Sequential MCP
- **Performance**: Keywords like "slow", "optimize", "bottleneck" ‚Üí ‚ö° performance persona + Playwright MCP

**Operation Type Classification**:
- **Analysis**: "analyze", "review", "understand" ‚Üí Sequential MCP + analyzer persona
- **Creation**: "create", "build", "implement" ‚Üí Magic MCP (if UI) or Context7 (patterns)
- **Modification**: "improve", "refactor", "optimize" ‚Üí Appropriate specialist persona
- **Debugging**: "troubleshoot", "fix", "debug" ‚Üí Sequential MCP + analyzer persona

#### Auto-Activation Logic

**High-Confidence Triggers** (90%+ activation):
```bash
/sg:analyze auth-system/ --focus security
# ‚Üí üõ°Ô∏è security persona + Sequential MCP + --validate flag
```

**Context-Based Activation**:
```bash
/sg:build react-components/
# ‚Üí üé® frontend persona + Magic MCP + --c7 flag (React docs)
```

**Performance-Based Activation**:
```bash
# When context usage >75%
/sg:analyze large-project/
# ‚Üí Auto-adds --uc flag for compression
```

### Routing Intelligence üö¶

The routing system uses dynamic decision trees to map detected patterns to optimal tool combinations.

#### Master Routing Table

| Request Pattern | Usually Auto-Activates | How Often | Why |
|----------------|----------------|------------|-----|
| "analyze architecture" | üèóÔ∏è architect + Sequential | Most times | Complex system analysis |
| "create UI component" | üé® frontend + Magic + --uc | Pretty often | Frontend domain with generation |
| "security audit" | üõ°Ô∏è security + Sequential | Most times | Security expertise needed |
| "debug complex issue" | üîç analyzer + Sequential | Often | Investigation methodology |
| "improve performance" | ‚ö° performance + Playwright | Pretty often | Performance expertise + testing |

#### Intelligent Coordination

**Multi-Server Operations**:
```bash
/sg:design user-dashboard --type api
```
**Orchestrator usually coordinates**:
- üèóÔ∏è architect persona (system design)
- üé® frontend persona (UI design) 
- Context7 MCP (framework patterns)
- Sequential MCP (design methodology)

**Fallback Strategies**:
- Context7 unavailable ‚Üí WebSearch for documentation ‚Üí Manual implementation
- Sequential timeout ‚Üí Native Gemini analysis ‚Üí Note limitations
- Magic failure ‚Üí Basic component generation ‚Üí Suggest manual enhancement

### Quality Gates & Validation Framework ‚úÖ

SuperGemini tries to implement an 8-step validation cycle for operations:

#### 8-Step Quality Process

1. **Syntax Validation** - Language parsers + Context7 standards
2. **Type Checking** - Sequential analysis + compatibility verification
3. **Linting** - Context7 rules + quality analysis
4. **Security Review** - Sequential analysis + OWASP compliance
5. **Testing** - Playwright E2E + coverage analysis (aiming for good coverage)
6. **Performance** - Sequential analysis + benchmarking
7. **Documentation** - Context7 patterns + completeness validation
8. **Integration** - Playwright testing + deployment validation

#### Validation Automation

**Continuous Integration**:
- CI/CD pipeline integration
- Progressive validation with early failure detection
- Evidence generation with comprehensive metrics

**Intelligent Monitoring**:
- Success rate tracking with ML prediction
- Adaptive validation based on historical patterns
- Automatic optimization of validation strategies

### Performance Optimization ‚ö°

The orchestrator tries to optimize for good performance through several strategies:

#### Resource Management

**Token Allocation**:
- Detection Engine: 1-2K tokens for pattern analysis
- Decision Trees: 500-1K tokens for routing logic
- MCP Coordination: Variable based on activated servers
- Reserve: 10% buffer for unexpected complexity

**Operation Batching**:
- **Parallel execution** when no dependencies exist
- **Context sharing** across related operations
- **Cache strategies** for successful routing patterns
- **Smart queuing** to prevent resource exhaustion

#### Advanced Orchestration

**Sub-Agent Delegation**:
```bash
# Auto-activates when >7 directories or >50 files detected
/sg:analyze monorepo/
# ‚Üí --wave-mode auto flag + systematic processing
```

**Wave Orchestration**:
```bash
# Auto-activates when complexity >0.7 + files >20 + operation types >2
/sg:improve legacy-system/
# ‚Üí --wave-mode auto + multi-stage execution
```

### Real-World Orchestration Examples üí°

#### Example 1: Security Analysis Request
```bash
/sg:analyze user-auth/ --focus security
```

**Orchestrator Analysis**:
- Domain: Security (high confidence)
- Complexity: Moderate (authentication system)
- Operation: Analysis + scanning

**Usually coordinates**:
- üõ°Ô∏è security persona (threat modeling perspective)
- Sequential MCP (systematic analysis)
- --validate flag (pre-operation safety check)
- Sequential analysis for complex security patterns

**Quality Gates**: All 8 steps with emphasis on security validation

#### Example 2: Frontend Performance Optimization
```bash
/sg:improve slow-dashboard/ --focus performance
```

**Orchestrator Analysis**:
- Domain: Frontend + Performance (dual expertise needed)
- Complexity: High (performance optimization)
- Operation: Improvement + validation

**Usually coordinates**:
- ‚ö° performance persona (primary)
- üé® frontend persona (secondary, if UI detected)
- Playwright MCP (performance testing)
- Sequential analysis for complex optimization

**Quality Gates**: Performance-focused validation with benchmarking

#### Example 3: Large Codebase Analysis  
```bash
/sg:analyze enterprise-monorepo/
```

**Orchestrator Analysis**:
- Scope: Large (>50 files detected)
- Complexity: High (enterprise-scale)
- Resources: High token usage predicted

**Usually coordinates**:
- --wave-mode auto flag (multi-stage processing)
- --uc flag (token optimization)
- üèóÔ∏è architect persona (system-level analysis)
- Sequential MCP (structured analysis)

**Quality Gates**: Distributed validation across sub-agents

### Orchestrator Configuration ‚öôÔ∏è

**Performance Settings**:
```yaml
orchestrator_config:
  enable_caching: true
  parallel_operations: true
  max_parallel: 3
  token_reserve: 10%
  emergency_threshold: 90%
```

**Intelligence Settings**:
```yaml
  learning_enabled: true
  confidence_threshold: 0.7
  pattern_detection: aggressive
  wave_score_threshold: 0.7
```

The orchestrator tries to learn from successful patterns and improve future routing decisions based on outcomes.

---

## Rules & Principles üìè

SuperGemini operates according to core rules and principles that ensure consistent, reliable, and helpful behavior. Understanding these helps you predict how SuperGemini will approach problems and why it makes certain decisions.

### Core Operational Rules ‚öñÔ∏è

These are the core rules that SuperGemini tries to follow:

#### File Operation Security üîê
- **Always Read before Write/Edit** - SuperGemini never modifies files without understanding current content
- **Use absolute paths only** - Prevents path traversal attacks and ensures reliable file operations
- **Never auto-commit** - SuperGemini won't commit changes to git unless explicitly requested
- **Prefer batch operations** - Multiple related changes are grouped for consistency

**Why this matters**: These rules prevent data loss, security vulnerabilities, and unintended modifications to your codebase.

#### Task Management Rules üìã
- **Evidence-based progress** - Tasks are only marked complete when there's measurable evidence
- **Single focus protocol** - Only one task is "in_progress" at a time for clarity
- **Quality gates** - All operations include validation steps before completion
- **Context retention** - Tries to preserve context well across operations

**Why this matters**: Ensures reliable progress tracking and prevents work from being lost or forgotten.

#### Framework Compliance Rules üéØ
- **Check dependencies first** - Always verify package.json/requirements.txt before using libraries
- **Follow existing patterns** - Respect project conventions, import styles, and architecture
- **Systematic codebase changes** - Complete discovery before making project-wide modifications
- **Validate completion** - Verify changes work and don't break existing functionality

**Why this matters**: Maintains code quality and consistency with your existing project structure.

### Development Principles üõ†Ô∏è

These principles guide how SuperGemini approaches development problems:

#### Evidence-Based Decision Making üìä
**Primary Directive**: "Evidence > assumptions | Code > documentation | Efficiency > verbosity"

- **Measure before optimizing** - Performance improvements based on actual metrics
- **Test hypotheses systematically** - Claims supported by verifiable data
- **Document decision rationale** - Clear reasoning for architectural choices
- **Learn from outcomes** - Continuous improvement based on results

**In practice**:
```bash
/sg:improve slow-api/ --focus performance
# ‚Üí Measures current performance, identifies bottlenecks, optimizes based on data
```

#### SOLID Design Principles üèóÔ∏è
- **Single Responsibility** - Each component has one reason to change
- **Open/Closed** - Open for extension, closed for modification
- **Liskov Substitution** - Derived classes substitutable for base classes
- **Interface Segregation** - No forced dependencies on unused interfaces
- **Dependency Inversion** - Depend on abstractions, not concretions

**Why SuperGemini follows these**: Leads to maintainable, scalable, and flexible code that's easier to understand and modify.

#### Quality Philosophy ‚ú®
- **Prevention over detection** - Build quality in rather than test it in
- **Simplicity over complexity** - Choose the simplest solution that works
- **Maintainability over cleverness** - Code should be easy to understand and modify
- **Security by default** - Implement secure patterns from the start

#### Senior Developer Mindset üéì
SuperGemini approaches problems like an experienced developer:

- **Systems thinking** - Consider impacts across the entire system
- **Long-term perspective** - Decisions evaluated against multiple time horizons
- **Risk calibration** - Distinguish between acceptable and unacceptable risks
- **Stakeholder awareness** - Balance technical perfection with practical constraints

### How Rules & Principles Affect You üí°

#### Predictable Behavior
Because SuperGemini follows consistent rules, you can predict how it will approach problems:

```bash
/sg:improve legacy-authentication/
```
**You can expect**:
- Reading existing code before suggesting changes
- Following your project's existing patterns
- Security-first approach (security persona likely activates)
- Evidence-based recommendations with reasoning
- Quality gates before marking improvements complete

#### Quality Assurance
The principles ensure high-quality outcomes:

- **Tries to avoid magic changes** - SuperGemini usually explains its reasoning
- **Aims for no breaking changes** - Tries to preserve existing functionality
- **Security-conscious** - Security principles are important
- **Debt-aware** - Tries to maintain or reduce complexity

#### Transparency
You should usually understand what SuperGemini is doing and why:

```bash
/sg:analyze --introspect complex-system/
```
**Shows you**:
- Decision-making process
- Rule application
- Principle adherence
- Alternative approaches considered

### Examples of Rules & Principles in Action üéØ

#### Example 1: Systematic Refactoring
**Request**: "Clean up this messy codebase"

**Rules Applied**:
- Complete discovery before changes (searches entire codebase)
- Read all files before modifications
- Follow existing project patterns
- Validate completion with evidence

**Principles Applied**:
- Simplicity over complexity (reduces unnecessary complexity)
- Evidence-based decisions (measures complexity before/after)
- Quality assurance (comprehensive testing)
- Long-term maintainability (considers future modifications)

#### Example 2: Security Implementation
**Request**: "Add authentication to our API"

**Rules Applied**:
- Security persona usually auto-activates
- Never compromise on security fundamentals
- Check existing patterns first
- Quality gates include security validation

**Principles Applied**:
- Security by default (implements secure patterns)
- Defense in depth (multiple security layers)
- Evidence-based approach (follows established security patterns)
- Systems thinking (considers impact on entire application)

#### Example 3: Performance Optimization
**Request**: "This page loads slowly"

**Rules Applied**:
- Measure before optimizing
- Evidence-based progress tracking
- Validate improvements with metrics
- Maintain existing functionality

**Principles Applied**:
- Measurement-driven optimization
- User experience focus
- Systematic methodology
- Prevention over detection (identifies root causes)

### Rule Enforcement & Quality Gates üö®

SuperGemini enforces rules through its quality gate system:

#### Enforcement Approach
- **Pre-operation validation** - Checks risks before starting
- **Real-time monitoring** - Tracks rule compliance during execution
- **Post-operation verification** - Confirms rules were followed
- **Evidence collection** - Documents compliance for transparency

#### When Rules Are Challenged
Sometimes rules might seem to conflict with immediate needs:

**Example**: "Just make this work quickly, don't worry about quality"

**SuperGemini's response**:
- Acknowledges the urgency
- Explains why quality rules matter for long-term success
- Offers compromise solutions that maintain essential rules
- Documents risks if quality standards are relaxed

### Principles That Guide Persona Behavior üé≠

Each persona follows the core principles but emphasizes different aspects:

- **üõ°Ô∏è Security persona**: Security > compliance > reliability > performance
- **‚ö° Performance persona**: Measure first > optimize critical path > user experience
- **üèóÔ∏è Architect persona**: Long-term maintainability > scalability > performance
- **üé® Frontend persona**: User needs > accessibility > performance > technical elegance

**Why this matters**: You can predict how different personas will prioritize trade-offs based on their core principles.

### Living Principles üå±

These rules and principles aren't set in stone. They evolve based on:

- **Community feedback** - Real-world usage patterns inform improvements
- **Outcome analysis** - Successful patterns are reinforced
- **Technology changes** - Principles adapt to new development practices
- **User needs** - Rules balance flexibility with consistency

The goal is to maintain helpful, predictable behavior while adapting to the changing landscape of software development.

---

## Getting Started Workflows üõ£Ô∏è

Now that you understand SuperGemini's components, let's look at practical workflows for different development scenarios. These patterns will help you get productive quickly.

### First-Time Setup üé¨

If you haven't installed SuperGemini yet, see the [Installation Guide](installation-guide.md). Once installed, here's how to get started:

#### Quick Verification
```bash
# Test basic functionality
/sg:help                    # Should show SuperGemini commands
/sg:analyze README.md       # Try analyzing a simple file
/sg:build --help           # Check command options
```

#### Understanding Auto-Activation
Try these commands to see how SuperGemini automatically chooses the right tools:

```bash
# Frontend work ‚Üí frontend persona + Magic MCP
/sg:build src/components/

# Security analysis ‚Üí security persona + Sequential MCP  
/sg:analyze auth/ --focus security

# Performance investigation ‚Üí performance persona + Playwright MCP
/sg:analyze --focus performance slow-endpoints/
```

Watch for auto-activated flags and personas in the output. This shows SuperGemini's intelligent routing in action.

### Development Workflow Patterns üîÑ

#### New Project Onboarding
When starting work on an unfamiliar project:

```bash
# 1. Load project context
/sg:load --deep --summary
# ‚Üí Gives overview of structure, dependencies, patterns

# 2. Analyze architecture  
/sg:analyze --focus architecture
# ‚Üí üèóÔ∏è architect persona provides system understanding

# 3. Check code quality
/sg:analyze --focus quality
# ‚Üí üß™ qa persona identifies potential issues

# 4. Review documentation
/sg:document README --type guide
# ‚Üí ‚úçÔ∏è scribe persona improves project documentation
```

#### Feature Development Cycle
For developing new features:

```bash
# 1. Design phase
/sg:design user-dashboard --type component
# ‚Üí üèóÔ∏è architect + üé® frontend personas coordinate

# 2. Implementation
/sg:build dashboard-components/ 
# ‚Üí üé® frontend persona + Magic MCP for UI generation

# 3. Testing
/sg:test --type e2e dashboard/
# ‚Üí üß™ qa persona + Playwright MCP for testing

# 4. Documentation  
/sg:document dashboard/ --type api
# ‚Üí ‚úçÔ∏è scribe persona creates comprehensive docs
```

#### Bug Investigation & Resolution
For systematic debugging:

```bash
# 1. Problem investigation
/sg:troubleshoot "login randomly fails" --seq
# ‚Üí üîç analyzer persona + Sequential MCP for methodology

# 2. Root cause analysis
/sg:analyze auth-flow/ --focus debugging
# ‚Üí Systematic investigation with evidence collection

# 3. Fix implementation
/sg:improve auth/ --safe-mode --validate
# ‚Üí Safe improvements with validation

# 4. Verification testing
/sg:test auth-flow/ --coverage
# ‚Üí Comprehensive testing to ensure fix works
```

#### Code Quality Improvement
For improving existing code:

```bash
# 1. Quality assessment
/sg:analyze legacy-code/ --focus quality
# ‚Üí üîÑ refactorer persona identifies improvement opportunities

# 2. Safe improvements
/sg:improve --preview legacy-code/
# ‚Üí See what would change before applying

# 3. Apply improvements
/sg:improve --safe legacy-code/
# ‚Üí Apply only low-risk improvements

# 4. Validate changes
/sg:test --coverage improved-code/
# ‚Üí Ensure improvements don't break functionality
```

### Common Workflow Combinations ü§ù

#### Security-First Development
```bash
# Development with security focus
/sg:analyze --persona-security --focus security
/sg:build --validate --safe-mode  
/sg:test --type security
/sg:git --persona-security --validate
```

#### Performance-Optimized Workflow
```bash
# Performance-focused development
/sg:analyze --focus performance --persona-performance
/sg:improve --type performance --benchmark
/sg:test --focus performance --play
/sg:test --focus performance --play
```

#### Team Collaboration Workflow
```bash
# Collaborative development patterns
/sg:analyze team-code/ --persona-qa --focus quality
/sg:document features/ --persona-scribe --type guide
/sg:git --smart-commit --branch-strategy
/sg:task status  # Check team progress
```

### Advanced Workflow Patterns üöÄ

#### Large Codebase Management
For working with enterprise-scale projects:

```bash
# Efficient large-scale analysis
/sg:analyze monorepo/ --wave-mode auto --uc --focus architecture
# ‚Üí Wave orchestration + compression + architectural focus

# Systematic improvements
/sg:improve legacy-system/ --wave-mode auto --safe-mode
# ‚Üí Multi-stage improvements with safety checks

# Comprehensive quality review
/sg:analyze enterprise-app/ --wave-strategy systematic --focus quality
# ‚Üí Distributed quality analysis
```

#### Legacy System Modernization
For updating old codebases:

```bash
# Assessment phase
/sg:analyze legacy/ --persona-architect --seq
# ‚Üí Deep architectural analysis

# Planning phase  
/sg:design modernization-strategy --type architecture
# ‚Üí Comprehensive modernization plan

# Implementation phase
/sg:improve legacy/ --wave-mode systematic --safe-mode --loop
# ‚Üí Iterative, safe improvements with validation

# Migration support
/sg:migrate --type framework legacy-to-modern/
# ‚Üí Framework migration assistance
```

#### Multi-Domain Projects
For projects spanning multiple technical domains:

```bash
# Coordinate across domains
/sg:analyze fullstack-app/ --all-mcp --wave-mode auto
# ‚Üí All MCP servers + parallel processing

# Domain-specific improvements
/sg:improve frontend/ --persona-frontend --magic
/sg:improve backend/ --persona-backend --c7  
/sg:improve infrastructure/ --persona-devops --seq

# Integration validation
/sg:test --type integration --play
# ‚Üí Comprehensive integration testing
```

### Workflow Optimization Tips üí°

#### Start Small, Scale Up
```bash
# Begin with focused scope
/sg:analyze single-component.js --focus quality

# Expand as needed
/sg:analyze entire-module/ --focus quality --wave-strategy progressive

# Scale to full system
/sg:analyze whole-project/ --wave-mode auto --uc
```

#### Use Progressive Enhancement
```bash
# Basic command
/sg:build project/

# Add intelligence
/sg:build project/ --seq --c7

# Full orchestration
/sg:build project/ --wave-mode auto --all-mcp --wave-mode auto
```

#### Combine Complementary Personas
```bash
# Security + Performance analysis
/sg:analyze api/ --persona-security
/sg:analyze api/ --persona-performance

# Architecture + Quality review
/sg:review system/ --persona-architect --focus architecture
/sg:review system/ --persona-qa --focus quality
```

### Troubleshooting Workflows üö®

#### When Commands Don't Work as Expected
```bash
# Debug with introspection
/sg:troubleshoot "command issues" --introspect
# ‚Üí Meta-cognitive analysis of what went wrong

# Try different approaches
/sg:analyze problem/ --persona-analyzer --seq
# ‚Üí Systematic investigation methodology

# Check framework status
/sg:load framework-status/ --summary
# ‚Üí Understand current SuperGemini state
```

#### When Performance is Slow
```bash
# Optimize for speed
/sg:analyze large-project/ --no-mcp --uc --scope module
# ‚Üí Disable extra features, compress output, limit scope

# Use delegation for large tasks
/sg:improve huge-codebase/ --wave-mode auto --concurrency 5
# ‚Üí Parallel processing with controlled concurrency
```

#### When Results Aren't Focused Enough
```bash
# Use specific focus flags
/sg:analyze code/ --focus security --scope file

# Activate appropriate personas manually
/sg:analyze frontend-code/ --persona-security  # Security view of frontend

# Combine multiple approaches
/sg:analyze --focus performance --persona-performance --play
```

### Building Your Own Workflows üõ†Ô∏è

#### Identify Your Common Patterns
Track what combinations work well for your specific needs:

```bash
# Security-focused API development
alias secure-api="/build api/ --persona-security --validate --c7"

# Performance-optimized frontend work  
alias perf-frontend="/build ui/ --persona-performance --magic --benchmark"

# Quality improvement workflow
alias quality-check="/scan --focus quality && /improve --safe-mode && /test --coverage"
```

#### Experiment with Flag Combinations
Try different combinations to find what works best:

```bash
# For learning: verbose explanations with docs
/sg:explain concept --persona-mentor --verbose --c7

# For safety: maximum validation and checking
/sg:improve critical-code/ --safe-mode --validate --preview

# For efficiency: compressed output with parallel processing
/sg:analyze big-project/ --uc --wave-mode auto --concurrency 3
```

Remember: SuperGemini learns from successful patterns, so the more you use effective combinations, the better it gets at auto-activating the right approach for your needs.

---

## Integration & Coordination ü§ù

Understanding how SuperGemini's components work together is key to using the framework effectively. This section shows you how commands, flags, personas, and MCP servers coordinate automatically - and how to control that coordination when needed.

### Auto-Coordination Examples ü§ñ

SuperGemini automatically coordinates components based on context. Here's how it works in practice:

#### Frontend Development Request
```bash
/sg:build react-dashboard/
```

**Automatic coordination**:
- **Command**: `/build` handles compilation and bundling
- **Persona**: üé® frontend auto-activates (React detected)
- **MCP**: Magic provides modern UI components
- **MCP**: Context7 provides React best practices 
- **Flags**: `--c7` auto-activates for framework docs

**Result**: React-optimized build with modern components, accessibility checks, and performance optimization.

#### Security Analysis Request
```bash
/sg:scan user-authentication/ --focus security
```

**Automatic coordination**:
- **Command**: `/scan` handles security scanning
- **Persona**: üõ°Ô∏è security auto-activates (security focus)
- **MCP**: Sequential provides systematic analysis
- **Flags**: `--validate` auto-activates (high-risk operation)
- **Flags**: Sequential analysis for complex security patterns

**Result**: Comprehensive security analysis with threat modeling, vulnerability detection, and compliance checking.

#### Performance Investigation
```bash
/sg:troubleshoot "API responses are slow"
```

**Automatic coordination**:
- **Command**: `/troubleshoot` handles investigation
- **Persona**: ‚ö° performance auto-activates (performance keywords)
- **Persona**: üîç analyzer provides investigation methodology
- **MCP**: Sequential structures the debugging process
- **MCP**: Playwright provides performance testing
- **Flags**: Sequential analysis for complex debugging

**Result**: Systematic performance investigation with metrics, bottleneck identification, and optimization recommendations.

### Manual Coordination Control üéõÔ∏è

Sometimes you want to override auto-coordination for specific needs:

#### Override Persona Selection
```bash
# View frontend code from security perspective
/sg:analyze react-components/ --persona-security
# ‚Üí Security analysis of UI components (XSS, data exposure, etc.)

# Apply architectural thinking to small utility
/sg:improve utility-function.js --persona-architect  
# ‚Üí Design patterns and extensibility for simple code
```

#### Control MCP Server Usage
```bash
# Disable all MCP servers for speed
/sg:analyze large-codebase/ --no-mcp
# ‚Üí 40-60% faster execution, native tools only

# Enable all MCP servers for comprehensive analysis
/sg:analyze complex-system/ --all-mcp
# ‚Üí Maximum capabilities, higher token usage

# Use specific MCP combinations
/sg:build ui-components/ --magic --c7 --no-seq
# ‚Üí UI generation + docs, skip complex analysis
```

#### Combine Multiple Perspectives
```bash
# Sequential analysis with different personas
/sg:analyze payment-system/ --persona-security     # Security view
/sg:analyze payment-system/ --persona-performance  # Performance view  
/sg:analyze payment-system/ --persona-architect    # Architecture view

# Or coordinate automatically
/sg:review payment-system/ --focus quality
# ‚Üí Auto-coordinates security + performance + architecture insights
```

### Flag Coordination Patterns üèÅ

Flags work together to create powerful combinations:

#### Safety-First Patterns
```bash
# Maximum safety for critical code
/sg:improve production-auth/ --safe-mode --validate --preview
# ‚Üí Conservative changes + risk assessment + preview before applying

# Safe exploration of large changes
/sg:improve legacy-system/ --wave-mode auto --safe-mode --validate
# ‚Üí Multi-stage improvements + safety checks + validation gates
```

#### Performance-Optimized Patterns  
```bash
# Fast execution for large operations
/sg:analyze huge-project/ --uc --no-mcp --scope module
# ‚Üí Compressed output + native tools + limited scope

# Efficient parallel processing
/sg:improve monorepo/ --wave-mode auto --uc --concurrency 5
# ‚Üí Parallel processing + compression + controlled resource usage
```

#### Learning-Focused Patterns
```bash
# Educational explanations with full context
/sg:explain complex-concept --persona-mentor --verbose --c7
# ‚Üí Educational approach + detailed explanations + official docs

# Deep understanding with transparency
/sg:analyze mysterious-code/ --persona-analyzer --seq-hard --introspect  
# ‚Üí Investigation methodology + deep analysis + thinking transparency
```

### MCP Server Coordination üîß

MCP servers often work together automatically:

#### Documentation + Analysis
```bash
/sg:improve old-react-code/
```
**MCP coordination**:
- Context7: Gets current React best practices
- Sequential: Analyzes code against modern patterns
- Magic: Suggests modern component patterns
- Result: Modernization with current standards

#### Testing + Performance
```bash
/sg:test dashboard/ --focus performance
```
**MCP coordination**:
- Sequential: Plans comprehensive test strategy
- Playwright: Executes performance testing
- Context7: Provides testing best practices
- Result: Performance testing with industry standards

#### Complex Problem Solving
```bash
/sg:troubleshoot "complex multi-service issue" --seq
```
**MCP coordination**:
- Sequential: Structures systematic investigation
- Context7: Provides service architecture patterns
- Playwright: Tests service interactions
- Result: Comprehensive multi-domain debugging

### Persona Collaboration Patterns üé≠

Personas automatically collaborate on complex requests:

#### Architecture + Security
```bash
/sg:design payment-api --type secure
```
**Persona collaboration**:
- üèóÔ∏è architect: System design and scalability
- üõ°Ô∏è security: Threat modeling and secure patterns
- ‚öôÔ∏è backend: API implementation patterns
- Result: Secure, scalable API design

#### Frontend + Performance  
```bash
/sg:build dashboard --focus performance
```
**Persona collaboration**:
- üé® frontend: UI/UX and accessibility
- ‚ö° performance: Optimization and metrics
- üèóÔ∏è architect: Component architecture  
- Result: Fast, accessible, well-structured dashboard

#### Quality + Refactoring
```bash
/sg:improve legacy-code/ --focus quality
```
**Persona collaboration**:
- üîÑ refactorer: Code quality and patterns
- üß™ qa: Testing and validation
- üèóÔ∏è architect: Structural improvements
- Result: Clean, tested, well-architected code

### Advanced Coordination Strategies üöÄ

#### Wave Orchestration
For complex multi-stage operations:

```bash
/sg:improve enterprise-system/ --wave-mode systematic
```

**Wave coordination**:
1. **Analysis Wave**: üîç analyzer + Sequential assess current state
2. **Planning Wave**: üèóÔ∏è architect + Context7 design improvements  
3. **Implementation Wave**: Appropriate specialists + tools implement changes
4. **Validation Wave**: üß™ qa + Playwright verify improvements
5. **Optimization Wave**: ‚ö° performance + metrics optimize results

#### Large-Scale Analysis
For complex projects:

```bash
/sg:analyze large-monorepo/ --wave-mode --systematic-waves
```

**Wave coordination**:
- **Analysis**: Systematic assessment of project structure
- **Processing**: Wave-based execution for better results
- **Integration**: MCP servers coordinate analysis
- **Results**: Comprehensive insights with domain expertise

#### Adaptive Intelligence
SuperGemini adapts coordination based on context:

**Development Phase Detection**:
- Planning phase ‚Üí üèóÔ∏è architect + ‚úçÔ∏è scribe emphasis
- Implementation phase ‚Üí Domain specialists + Magic/Context7
- Testing phase ‚Üí üß™ qa + Playwright emphasis
- Deployment phase ‚Üí üöÄ devops + validation emphasis

**Complexity-Based Scaling**:
- Simple tasks ‚Üí Direct execution
- Moderate complexity ‚Üí Persona + MCP coordination
- High complexity ‚Üí Wave orchestration with systematic approach

### Coordination Troubleshooting üîß

#### When Auto-Coordination Goes Wrong
```bash
# Too many tools activated (slow/expensive)
/sg:analyze simple-file.js --no-mcp --answer-only
# ‚Üí Minimal tooling for simple tasks

# Wrong persona activated
/sg:analyze backend-api/ --persona-security  
# ‚Üí Override with explicit persona choice

# Not enough analysis depth
/sg:troubleshoot complex-issue --seq --all-mcp
# ‚Üí Force maximum capabilities
```

#### Optimizing Coordination
```bash
# Start simple, add complexity as needed
/sg:analyze code.js                    # Basic analysis
/sg:analyze code.js --seq            # Add thinking
/sg:analyze code.js --seq --c7       # Add documentation
/sg:analyze code.js --seq --c7 --seq # Add systematic analysis
```

#### Understanding Coordination Decisions
```bash
# See why certain tools were chosen
/sg:analyze complex-system/ --introspect
# ‚Üí Shows decision-making process and tool selection reasoning
```

### Best Practices for Integration üí°

#### Let Auto-Coordination Work First
- Trust SuperGemini's automatic tool selection
- Override only when you need specific perspectives
- Start with simple commands and add flags as needed

#### Understand Flag Interactions
- Some flags override others (`--no-mcp` overrides `--c7`, `--seq`)
- Safety flags take precedence over optimization flags
- Persona flags can be overridden by more specific persona requests

#### Use Appropriate Scope
- File-level: Single persona + minimal MCP
- Module-level: Domain personas + relevant MCP
- System-level: Multiple personas + full MCP coordination

#### Monitor Resource Usage
- Large operations ‚Üí Use `--uc` and `--wave-mode`
- Simple tasks ‚Üí Use `--no-mcp` and `--answer-only`
- Critical operations ‚Üí Use `--safe-mode` and `--validate`

The key is understanding that SuperGemini's intelligence comes from the coordination between its components. The automatic coordination works well most of the time, but knowing how to control it gives you the flexibility to handle any situation.

---

## Practical Examples üí°

Real-world scenarios showing SuperGemini in action. These examples demonstrate how different components work together to solve common development problems.

### Scenario 1: New Team Member Onboarding üëã

**Situation**: You're starting work on an unfamiliar React/Node.js e-commerce project.

#### Step 1: Project Understanding
```bash
/sg:load --deep --summary
```
**What happens**:
- üîç analyzer persona activates (investigation needed)
- Sequential MCP structures the analysis  
- Context7 MCP identifies framework patterns
- Creates comprehensive project overview

**Output**: Project structure, tech stack, dependencies, and architecture summary.

#### Step 2: Code Quality Assessment
```bash
/sg:analyze --focus quality
```
**Auto-coordination**:
- üß™ qa persona activates (quality focus)
- Sequential MCP provides systematic analysis
- Scans for code quality, security, and performance issues
- Generates actionable improvement recommendations

**Output**: Quality report with specific issues and improvement suggestions.

#### Step 3: Architecture Understanding
```bash
/sg:analyze --focus architecture --persona-architect
```
**What happens**:
- üèóÔ∏è architect persona provides system design perspective
- Context7 MCP brings in React/Node.js architectural patterns
- Sequential MCP structures the architectural analysis
- Identifies design patterns, data flow, and component relationships

**Output**: Architectural overview with design patterns and system relationships.

#### Step 4: Getting Started Guide
```bash
/sg:document onboarding --type guide --persona-scribe
```
**What happens**:
- ‚úçÔ∏è scribe persona creates professional documentation
- Context7 MCP provides documentation standards
- Synthesizes previous analysis into newcomer-friendly guide
- Includes setup instructions and key concepts

**Output**: Comprehensive onboarding guide for future team members.

**Time saved**: What normally takes 2-3 days of exploration is condensed into a comprehensive understanding in about 30 minutes.

### Scenario 2: Security Vulnerability Investigation üõ°Ô∏è

**Situation**: Security scanner flagged potential issues in user authentication system.

#### Step 1: Security-Focused Analysis
```bash
/sg:scan auth-system/ --persona-security --focus security
```
**Auto-coordination**:
- üõ°Ô∏è security persona activates (security expertise)
- Sequential MCP provides systematic threat modeling
- Context7 MCP brings in OWASP and security best practices
- `--validate` flag auto-activates (high-risk operation)

**Output**: Detailed security analysis with threat assessment and vulnerability prioritization.

#### Step 2: Root Cause Investigation  
```bash
/sg:troubleshoot "JWT token exposure in logs" --seq --seq
```
**What happens**:
- üîç analyzer persona provides investigation methodology
- `--seq` flag enables deep analysis
- Sequential MCP structures the debugging process
- Traces data flow and identifies exposure points

**Output**: Root cause analysis with evidence trail and impact assessment.

#### Step 3: Secure Implementation
```bash
/sg:improve auth-system/ --focus security --safe-mode --validate
```
**Auto-coordination**:
- üõ°Ô∏è security persona maintains security focus
- `--safe-mode` ensures conservative changes
- `--validate` confirms changes before applying
- Context7 MCP provides secure coding patterns

**Output**: Security improvements with minimal risk and comprehensive validation.

#### Step 4: Security Testing
```bash
/sg:test auth-system/ --type security --play
```
**What happens**:
- üß™ qa persona provides testing expertise  
- Playwright MCP executes security testing scenarios
- Tests authentication flows, session management, and access controls
- Validates security improvements are working

**Output**: Comprehensive security test results with evidence of improvements.

**Risk reduction**: Systematic approach reduces chance of missing security issues and ensures comprehensive coverage.

### Scenario 3: Performance Optimization Sprint ‚ö°

**Situation**: E-commerce dashboard is loading slowly, affecting user experience.

#### Step 1: Performance Analysis
```bash
/sg:analyze dashboard/ --focus performance --persona-performance
```
**Auto-coordination**:
- ‚ö° performance persona activates (performance expertise)
- Playwright MCP provides performance metrics and testing
- Context7 MCP brings in React performance best practices
- `--seq-hard` auto-activates (complex performance analysis)

**Output**: Performance bottleneck identification with metrics and prioritized optimization opportunities.

#### Step 2: Frontend Performance Deep Dive
```bash
/sg:analyze frontend/ --persona-frontend --focus performance --play
```
**What happens**:
- üé® frontend persona provides UI/UX perspective
- ‚ö° performance persona coordinates (dual expertise)
- Playwright MCP measures Core Web Vitals, bundle sizes, render times
- Magic MCP suggests modern optimization patterns

**Output**: Frontend-specific performance analysis with accessibility and user experience considerations.

#### Step 3: Backend API Performance
```bash
/sg:analyze api/ --persona-backend --focus performance
```
**Auto-coordination**:
- ‚öôÔ∏è backend persona provides server-side expertise
- Sequential MCP analyzes database queries and API patterns
- Context7 MCP provides Node.js/Express optimization patterns
- Identifies slow queries, inefficient endpoints, and caching opportunities

**Output**: Backend performance analysis with database and API optimization recommendations.

#### Step 4: Systematic Optimization
```bash
/sg:improve dashboard/ --focus performance --loop --iterations 3
```
**What happens**:
- ‚ö° performance persona leads optimization
- `--loop` enables iterative improvement
- Each iteration: optimize ‚Üí measure ‚Üí validate ‚Üí improve
- Progressive enhancement with metrics validation

**Output**: Iterative performance improvements with measurable results after each cycle.

#### Step 5: Performance Testing Validation
```bash
/sg:test dashboard/ --focus performance --play --benchmark
```
**What happens**:
- Playwright MCP executes comprehensive performance testing
- Tests on multiple devices, network conditions, and browsers
- Measures Core Web Vitals, load times, and user interaction metrics
- Validates improvements meet performance budgets

**Output**: Performance test results proving optimization effectiveness.

**Performance gain**: Systematic approach typically achieves 40-70% performance improvements with measurable validation.

### Scenario 4: Legacy Code Modernization üîÑ

**Situation**: 5-year-old React application needs modernization to current standards.

#### Step 1: Legacy Assessment
```bash
/sg:analyze legacy-app/ --persona-architect --seq
```
**Auto-coordination**:
- üèóÔ∏è architect persona provides structural analysis
- `--seq` enables maximum analysis depth
- Context7 MCP compares against current React patterns
- Sequential MCP provides systematic modernization assessment

**Output**: Comprehensive legacy analysis with modernization roadmap and risk assessment.

#### Step 2: Modernization Planning
```bash
/sg:design modernization-strategy --type architecture --persona-architect
```
**What happens**:
- üèóÔ∏è architect persona designs migration strategy
- Context7 MCP provides current React ecosystem patterns
- Sequential MCP structures the modernization plan
- Identifies migration phases, dependencies, and risks

**Output**: Detailed modernization plan with phased approach and risk mitigation.

#### Step 3: Safe Incremental Improvements
```bash
/sg:improve legacy-components/ --safe-mode --wave-mode systematic --loop
```
**Auto-coordination**:
- üîÑ refactorer persona leads code improvements
- `--safe-mode` ensures minimal risk
- `--wave-mode systematic` enables multi-stage improvements
- `--loop` allows iterative refinement
- Multiple personas coordinate: architect, frontend, qa

**Output**: Systematic modernization with safety checks and progressive enhancement.

#### Step 4: Testing Modernization
```bash
/sg:test modernized-app/ --type integration --coverage --play
```
**What happens**:
- üß™ qa persona ensures quality throughout modernization
- Playwright MCP provides comprehensive testing
- Tests legacy compatibility and new functionality
- Validates modernization doesn't break existing features

**Output**: Comprehensive test results proving modernization success.

**Modernization success**: Systematic approach reduces modernization risk by 80% and ensures compatibility.

### Scenario 5: Multi-Team API Design üåê

**Situation**: Designing a new microservice API that multiple teams will consume.

#### Step 1: Requirements Analysis
```bash
/sg:design user-service-api --type api --persona-backend
```
**Auto-coordination**:
- ‚öôÔ∏è backend persona provides API design expertise
- üèóÔ∏è architect persona coordinates for system integration
- Context7 MCP provides API design best practices
- Sequential MCP structures requirement analysis

**Output**: Comprehensive API design with endpoints, data models, and integration patterns.

#### Step 2: Security Review
```bash
/sg:review api-design/ --persona-security --focus security
```
**What happens**:
- üõ°Ô∏è security persona evaluates API security
- Reviews authentication, authorization, and data protection
- Context7 MCP provides OWASP API security guidelines
- Identifies security requirements and threat vectors

**Output**: Security assessment with hardening recommendations and compliance requirements.

#### Step 3: Performance Considerations
```bash
/sg:analyze api-design/ --persona-performance --focus performance
```
**Auto-coordination**:
- ‚ö° performance persona evaluates scalability
- Analyzes endpoint performance, caching strategies, rate limiting
- Context7 MCP provides high-performance API patterns
- Projects performance under load

**Output**: Performance analysis with scalability recommendations and optimization strategies.

#### Step 4: Documentation for Multiple Teams
```bash
/sg:document api/ --type api --persona-scribe --detailed
```
**What happens**:
- ‚úçÔ∏è scribe persona creates professional API documentation
- Context7 MCP provides API documentation standards
- Creates examples, integration guides, and troubleshooting
- Tailored for multiple consuming teams

**Output**: Comprehensive API documentation with examples, integration guides, and best practices.

#### Step 5: Implementation Validation
```bash
/sg:build api-implementation/ --validate --test-coverage
```
**Auto-coordination**:
- ‚öôÔ∏è backend persona implements API patterns
- üß™ qa persona ensures quality and testing
- Sequential MCP validates implementation against design
- Comprehensive testing and validation

**Output**: Production-ready API implementation with comprehensive testing and validation.

**Collaboration efficiency**: Multi-persona coordination reduces design iteration cycles by 60% and improves cross-team alignment.

### Common Pattern Recognition üîç

These examples show recurring patterns in how SuperGemini components coordinate:

#### Investigation ‚Üí Analysis ‚Üí Implementation ‚Üí Validation
Most complex workflows follow this pattern with appropriate personas and tools for each phase.

#### Multi-Persona Coordination
Complex problems benefit from multiple perspectives (security + performance, architecture + frontend, etc.).

#### Progressive Enhancement
Starting simple and using Sequential analysis when needed.

#### Safety-First Approach
Critical operations automatically include validation and safety checks (`--safe-mode`, `--validate`).

#### Context-Aware Tool Selection
SuperGemini automatically chooses appropriate MCP servers and flags based on detected context.

These examples demonstrate that SuperGemini's value comes from intelligent coordination of its components rather than any single capability. The framework adapts to your needs while maintaining consistent quality and safety standards.

---

## Tips & Best Practices üéØ

Based on real-world usage patterns and successful workflows, here are practical tips for getting the most out of SuperGemini.

### Starting Out Successfully üöÄ

#### Begin with Simple Commands
```bash
# Start here - basic functionality
/sg:help
/sg:analyze README.md
/sg:build --help

# Not here - complex orchestration
/sg:improve entire-codebase/ --wave-mode force --all-mcp --wave-mode auto
```

**Why**: Understanding basic behavior before adding complexity prevents confusion and helps you learn the framework gradually.

#### Trust Auto-Activation First
```bash
# Let SuperGemini choose tools
/sg:analyze auth-system/  
# ‚Üí Watch what auto-activates (likely security persona + validation)

# Then experiment with manual control
/sg:analyze auth-system/ --persona-performance
# ‚Üí See different perspective on same code
```

**Why**: Auto-activation usually gets it right and shows you optimal tool combinations for different scenarios.

#### Use Preview and Safe Modes
```bash
# See what would happen first
/sg:improve messy-code.js --preview

# Apply changes safely  
/sg:improve messy-code.js --safe-mode

# For critical code, use both
/sg:improve production-auth/ --preview --safe-mode --validate
```

**Why**: Prevents unintended changes and helps you understand what SuperGemini will do before it does it.

### Flag Usage Patterns üèÅ

#### Start Simple, Add Complexity
```bash
# Basic command
/sg:analyze complex-system/

# Add thinking if needed
/sg:analyze complex-system/ --seq

# Add documentation if external libraries involved
/sg:analyze complex-system/ --seq --c7

# Full analysis for critical systems
/sg:analyze complex-system/ --seq-hard --c7 --seq --validate
```

**Why**: Incremental complexity helps you understand what each flag adds and avoids over-engineering simple problems.

#### Common Flag Combinations That Work
```bash
# Safe improvement workflow
/sg:improve --preview ‚Üí /improve --safe-mode ‚Üí /test --coverage

# Deep investigation workflow  
/sg:troubleshoot issue --seq --seq ‚Üí /analyze affected-code/ --focus quality

# Learning and documentation workflow
/sg:explain concept --persona-mentor --verbose --c7

# Performance optimization workflow
/sg:analyze --focus performance --persona-performance --play
```

**Why**: These combinations are proven patterns that work well together and don't conflict.

#### Avoid Flag Conflicts
```bash
# ‚ùå Conflicting flags
/sg:analyze code/ --no-mcp --c7  # --no-mcp overrides --c7

# ‚ùå Counterproductive combinations
/sg:analyze small-file.js --seq --all-mcp  # Overkill for simple tasks

# ‚úÖ Sensible combinations
/sg:analyze large-system/ --seq --wave-mode auto  # Appropriate for complexity
/sg:analyze simple-utility.js --answer-only       # Appropriate for simplicity
```

**Why**: Understanding flag precedence and interactions prevents unexpected behavior and wasted resources.

### Persona Optimization üé≠

#### Let Domain Auto-Activation Work
```bash
# These will automatically get the right persona
/sg:build react-components/     # ‚Üí frontend persona
/sg:scan auth/ --focus security # ‚Üí security persona  
/sg:troubleshoot slow-api/      # ‚Üí performance + analyzer personas
```

**Why**: Auto-activation is based on proven patterns and usually selects the most appropriate expertise.

#### Manual Override for Different Perspectives
```bash
# Get different viewpoints on same code
/sg:analyze payment-flow/ --persona-security    # Security perspective
/sg:analyze payment-flow/ --persona-performance # Performance perspective
/sg:analyze payment-flow/ --persona-architect   # Architecture perspective
```

**Why**: Different personas provide unique insights that can reveal issues or opportunities others might miss.

#### Use Appropriate Personas for Project Phases
```bash
# Planning phase
/sg:design new-feature --persona-architect

# Implementation phase  
/sg:build feature/ --persona-frontend  # or backend, etc.

# Testing phase
/sg:test feature/ --persona-qa

# Documentation phase
/sg:document feature/ --persona-scribe
```

**Why**: Each project phase benefits from different types of expertise and perspectives.

### MCP Server Strategy üîß

#### Understand When Each Server Helps
- **Context7**: When working with frameworks, libraries, or need official documentation
- **Sequential**: For complex debugging, systematic analysis, or architectural decisions  
- **Magic**: For UI component generation, design systems, or frontend development
- **Playwright**: For testing, performance measurement, or browser automation

#### Optimize for Performance vs. Capabilities
```bash
# Fast execution for simple tasks
/sg:analyze simple-script.js --no-mcp

# Comprehensive analysis for complex problems
/sg:analyze complex-system/ --all-mcp --seq-hard

# Balanced approach for most work
/sg:analyze typical-component/ --c7  # Just documentation lookup
```

**Why**: Matching MCP usage to task complexity optimizes both speed and quality of results.

### Workflow Optimization üìà

#### Use Progressive Enhancement
```bash
# Level 1: Basic analysis
/sg:analyze component.js

# Level 2: Add thinking if complex
/sg:analyze component.js --seq

# Level 3: Add documentation for frameworks
/sg:analyze component.js --seq --c7

# Level 4: Full analysis for critical code
/sg:analyze component.js --seq-hard --c7 --seq --validate
```

**Why**: Start with what you need and add complexity only when necessary. Prevents over-engineering and saves time.

#### Batch Related Operations
```bash
# ‚úÖ Efficient: Related operations together
/sg:analyze auth-system/ --focus security
/sg:improve auth-system/ --focus security --safe-mode  
/sg:test auth-system/ --type security

# ‚ùå Inefficient: Scattered operations
/sg:analyze auth-system/
/sg:review different-system/
/sg:improve auth-system/  # Context lost between operations
```

**Why**: Batching related work maintains context and allows SuperGemini to build on previous analysis.

#### Use Appropriate Scope
```bash
# File-level for specific issues
/sg:improve single-component.js --focus performance

# Module-level for related functionality
/sg:analyze user-auth/ --scope module

# Project-level for architectural concerns
/sg:analyze --scope project --focus architecture

# System-level only when necessary
/sg:analyze --scope system --wave-mode auto --uc
```

**Why**: Matching scope to problem prevents both under-analysis and resource waste.

### Performance and Efficiency üèÉ‚Äç‚ôÇÔ∏è

#### Manage Context and Token Usage
```bash
# For large operations, use compression
/sg:analyze huge-codebase/ --uc --wave-mode auto

# For repeated analysis, cache results
/sg:load project-context/  # Cache project understanding
/sg:analyze specific-issue/  # Build on cached context

# For simple questions, minimize overhead
/sg:explain quick-concept --answer-only --no-mcp
```

**Why**: Token efficiency keeps operations fast and prevents context overflow in large projects.

#### Use Wave Mode for Large Projects
```bash
# Automatically activate wave mode for complexity
/sg:analyze monorepo/ --wave-mode auto

# Force wave mode for systematic analysis
/sg:analyze large-project/ --wave-mode force --wave-strategy systematic

# Disable wave mode for simple projects
/sg:analyze small-app/ --wave-mode off
```

**Why**: Wave orchestration provides better results (30-50%) for large-scale operations through multi-stage processing.

#### Optimize Command Sequences
```bash
# ‚úÖ Efficient sequence
/sg:load project/           # Understand context once
/sg:analyze --focus quality # Build on understanding
/sg:improve --safe-mode     # Apply improvements
/sg:test --coverage         # Validate changes

# ‚ùå Inefficient sequence  
/sg:analyze file1.js
/sg:analyze file2.js        # Duplicate setup
/sg:analyze file3.js        # Lost optimization opportunities
```

**Why**: Sequential commands can build on each other's context and analysis for better results.

### Quality and Safety üõ°Ô∏è

#### Always Validate Important Changes
```bash
# For production code
/sg:improve production-auth/ --safe-mode --validate --preview

# For experimental features
/sg:improve experimental-feature/ --validate

# For learning/exploration
/sg:improve test-code/ --preview  # See what it would do
```

**Why**: Validation prevents breaking changes and helps you understand the impact of modifications.

#### Use Quality Gates Effectively
```bash
# Let quality gates run automatically
/sg:build production-app/  # 8-step validation process runs

# Add extra validation for critical systems
/sg:build payment-system/ --validate --safe-mode

# Skip validation only for experimental work
/sg:build prototype/ --no-validate  # Use sparingly
```

**Why**: Quality gates catch issues early when they're cheaper and easier to fix.

#### Maintain Evidence Trail
```bash
# Commands that provide evidence
/sg:analyze --focus performance  # ‚Üí Performance metrics
/sg:test --coverage             # ‚Üí Coverage reports  
/sg:scan --focus security       # ‚Üí Security assessment

# Use introspection for complex decisions
/sg:analyze complex-system/ --introspect  # ‚Üí Decision reasoning
```

**Why**: Evidence-based development leads to better decisions and easier debugging when issues arise.

### Learning and Growth üìö

#### Use Mentor Persona for Learning
```bash
# Learn new concepts
/sg:explain GraphQL --persona-mentor --verbose

# Understand complex code
/sg:analyze complex-algorithm.js --persona-mentor

# Get step-by-step guidance
/sg:build new-feature/ --persona-mentor --plan
```

**Why**: Mentor persona optimizes for understanding and knowledge transfer rather than just task completion.

#### Experiment with Different Approaches
```bash
# Try different personas on same problem
/sg:analyze api-design/ --persona-architect
/sg:analyze api-design/ --persona-security
/sg:analyze api-design/ --persona-performance

# Compare tool combinations
/sg:build app/ --magic --c7
/sg:build app/ --no-mcp --uc  # Faster but simpler
```

**Why**: Understanding different approaches helps you choose the best tools for different situations.

#### Build Your Own Patterns
```bash
# Identify what works for your workflow
# Security-focused API development
/sg:design api --persona-security --validate
/sg:build api --persona-backend --c7
/sg:test api --type security --play

# Create your own efficient combinations
/sg:analyze code/ --seq --c7 --safe-mode  # Your personal "thorough analysis"
```

**Why**: Developing your own proven patterns increases productivity and ensures consistent quality.

### Common Pitfalls to Avoid ‚ö†Ô∏è

#### Don't Over-Engineer Simple Tasks
```bash
# ‚ùå Overkill for simple tasks
/sg:analyze simple-utility.js --seq --all-mcp --wave-mode force

# ‚úÖ Appropriate for simple tasks  
/sg:analyze simple-utility.js --focus quality
```

#### Don't Ignore Auto-Activation Wisdom
```bash
# ‚ùå Fighting the system
/sg:build react-app/ --persona-backend --no-magic  # Wrong tools for the job

# ‚úÖ Working with the system
/sg:build react-app/  # Let frontend persona and Magic activate automatically
```

#### Don't Skip Safety for Speed
```bash
# ‚ùå Risky for important code
/sg:improve production-auth/ --force --no-validate

# ‚úÖ Balanced approach
/sg:improve production-auth/ --safe-mode --validate  # Safer but still efficient
```

#### Don't Use Flags You Don't Understand
```bash
# ‚ùå Cargo cult flag usage
/sg:command --random-flags-that-look-important

# ‚úÖ Understand what each flag does
/sg:command --seq  # Because I need deeper analysis
/sg:command --c7     # Because I'm working with external libraries
```

### Measuring Success üìä

Track what works well for your specific needs:

- **Speed**: How quickly do different flag combinations complete?
- **Quality**: Which approaches produce better results for your type of work?
- **Learning**: Which combinations help you understand problems better?
- **Safety**: Which patterns prevent issues in your environment?

Remember: SuperGemini learns from successful patterns, so using effective combinations consistently helps the framework get better at auto-activation for your specific workflow.

---

## Troubleshooting & Common Issues üö®

When SuperGemini doesn't work as expected, here's how to diagnose and fix common problems.

### Command Issues üõ†Ô∏è

#### Commands Not Working as Expected

**Problem**: Command produces unexpected results or seems to ignore your request.

**Diagnosis**:
```bash
# Check what auto-activated
/sg:analyze code.js --introspect
# ‚Üí Shows decision-making process

# Try with explicit control
/sg:analyze code.js --persona-analyzer --seq --seq
# ‚Üí Override auto-activation
```

**Solutions**:
```bash
# Be more specific about what you want
/sg:improve code.js --focus performance --safe-mode

# Use preview to understand what will happen
/sg:improve code.js --preview

# Start simple and add complexity
/sg:analyze code.js                    # Basic
/sg:analyze code.js --seq            # Add depth
/sg:analyze code.js --seq --c7       # Add documentation
```

**Common Causes**:
- Auto-activation chose different tools than you expected
- Request was too vague for SuperGemini to understand intent
- Complexity mismatch (simple request with complex flags or vice versa)

#### Commands Running Too Slowly

**Problem**: Operations take much longer than expected.

**Diagnosis**:
```bash
# Check what's activated
/sg:analyze large-project/ --introspect
# ‚Üí See what tools and servers are being used

# Monitor resource usage
/sg:analyze large-project/ --verbose
# ‚Üí Shows detailed execution steps
```

**Solutions**:
```bash
# Optimize for speed
/sg:analyze large-project/ --uc --no-mcp --scope module

# Use delegation for large operations
/sg:analyze huge-codebase/ --wave-mode auto --concurrency 3

# Reduce scope
/sg:analyze specific-component.js  # Instead of entire project

# Disable expensive features
/sg:analyze code/ --no-mcp --answer-only
```

**Performance Optimization Priority**:
1. Reduce scope (`--scope file` vs `--scope project`)
2. Use compression (`--uc`)
3. Disable MCP servers (`--no-mcp`)
4. Use wave mode (`--wave-mode auto`)
5. Use answer-only mode (`--answer-only`)

#### Commands Producing Too Much Output

**Problem**: Information overload, hard to find relevant information.

**Solutions**:
```bash
# Use compression
/sg:analyze large-system/ --uc

# Be more specific about focus
/sg:analyze system/ --focus security  # Instead of general analysis

# Use answer-only for simple questions
/sg:explain concept --answer-only

# Limit scope
/sg:analyze --scope file specific-issue.js
```

### Flag Issues üèÅ

#### Flag Conflicts and Unexpected Behavior

**Problem**: Flags don't seem to work or produce unexpected results.

**Common Conflicts**:
```bash
# ‚ùå These conflict
/sg:command --no-mcp --c7        # --no-mcp overrides --c7
/sg:command --answer-only --plan # --answer-only skips planning
/sg:command --uc --verbose       # --uc overrides --verbose

# ‚úÖ These work together
/sg:command --seq --c7 --seq   # Complementary capabilities
/sg:command --safe-mode --validate --preview  # Layered safety
```

**Flag Precedence Order**:
1. Safety flags (`--safe-mode`) > optimization flags
2. Explicit flags > auto-activation  
3. `--no-mcp` overrides all individual MCP flags
4. Last specified persona wins
5. Scope: system > project > module > file

**Diagnosis**:
```bash
# Check what flags are actually active
/sg:command args --introspect
# ‚Üí Shows final flag configuration after precedence resolution
```

#### Auto-Activation Issues

**Problem**: Wrong flags or personas auto-activate.

**Solutions**:
```bash
# Override auto-activation explicitly
/sg:analyze frontend-code/ --persona-security  # Force security view
/sg:build project/ --no-mcp                    # Force native tools only

# Use more specific language
/sg:analyze "security vulnerabilities in auth system"  # Clear intent
# vs
/sg:analyze auth system                                # Ambiguous

# Check what keywords trigger auto-activation
/sg:help analyze  # Shows auto-activation patterns
```

**Auto-Activation Debugging**:
```bash
# See why certain flags activated
/sg:troubleshoot "why did --seq-hard activate?" --introspect
```

### Persona Issues üé≠

#### Wrong Persona Activated

**Problem**: SuperGemini uses the wrong specialist for your needs.

**Diagnosis**:
```bash
# Check what triggered persona activation
/sg:analyze code/ --introspect
# ‚Üí Shows persona selection reasoning
```

**Solutions**:
```bash
# Override with explicit persona
/sg:analyze backend-api/ --persona-security  # Security view of backend code
/sg:analyze ui-component/ --persona-performance  # Performance view of frontend

# Use more specific language
/sg:analyze "security issues in payment processing"  # Triggers security persona
/sg:analyze "slow database queries"                  # Triggers performance persona

# Try different personas for different perspectives
/sg:analyze payment-system/ --persona-security    # Security view
/sg:analyze payment-system/ --persona-architect   # Architecture view
```

#### Persona Doesn't Seem Active

**Problem**: Expected persona behavior but getting generic responses.

**Check Persona Activation**:
```bash
# Verify persona is active
/sg:analyze auth/ --persona-security --introspect
# ‚Üí Should show security-focused reasoning

# Check if domain keywords are clear
/sg:scan authentication --focus security  # Should auto-activate security persona
```

**Solutions**:
```bash
# Be explicit about persona and focus
/sg:analyze code/ --persona-security --focus security

# Use appropriate commands for personas
/sg:scan --persona-security     # Security scanning
/sg:test --persona-qa           # Quality-focused testing
/sg:document --persona-scribe   # Professional documentation
```

### MCP Server Issues üîß

#### MCP Servers Not Activating

**Problem**: Expected MCP capabilities but they don't seem to work.

**Diagnosis**:
```bash
# Check MCP server status
/sg:troubleshoot "MCP servers not working" --introspect

# Verify MCP installation
/sg:load --summary  # Should show available MCP servers

# Test specific servers
/sg:analyze react-app/ --c7     # Should use Context7
/sg:troubleshoot issue --seq    # Should use Sequential
/sg:build ui/ --magic           # Should use Magic
/sg:test app/ --play            # Should use Playwright
```

**Common Solutions**:
```bash
# Force MCP activation
/sg:analyze code/ --all-mcp

# Check if servers are disabled
/sg:analyze code/ --c7  # If this doesn't work, Context7 may be unavailable

# Use fallback approaches
/sg:analyze react-app/ --no-mcp  # Use native tools if MCP unavailable
```

#### MCP Servers Too Slow

**Problem**: MCP server integration causes slow performance.

**Solutions**:
```bash
# Disable MCP for speed
/sg:analyze large-project/ --no-mcp

# Use selective MCP activation
/sg:analyze react-code/ --magic --no-seq  # Only UI generation, skip analysis

# Optimize MCP usage
/sg:analyze code/ --uc --c7  # Compression + documentation only
```

### Performance Issues ‚ö°

#### Operations Using Too Many Tokens

**Problem**: Hitting context limits or expensive operations.

**Solutions**:
```bash
# Enable compression automatically
/sg:analyze huge-project/ --uc

# Reduce scope
/sg:analyze --scope module specific-area/
/sg:analyze --scope file specific-file.js

# Use delegation
/sg:analyze large-codebase/ --wave-mode auto --uc

# Disable expensive features
/sg:analyze code/ --no-mcp --answer-only
```

#### Memory or Resource Issues

**Problem**: Operations failing or very slow due to resource constraints.

**Solutions**:
```bash
# Reduce concurrency
/sg:analyze large-project/ --wave-mode auto --concurrency 1

# Use safe mode
/sg:improve large-system/ --safe-mode  # More conservative resource usage

# Break work into smaller chunks
/sg:analyze module1/
/sg:analyze module2/
/sg:analyze module3/
# Instead of /analyze entire-project/
```

### Quality and Safety Issues üõ°Ô∏è

#### Unsafe or Risky Suggestions

**Problem**: SuperGemini suggests changes that seem risky.

**Always Use Safety Features**:
```bash
# Preview before applying
/sg:improve important-code/ --preview

# Use safe mode for critical code
/sg:improve production-auth/ --safe-mode

# Add validation
/sg:improve system/ --validate --safe-mode

# Use iterative approach
/sg:improve complex-system/ --loop --safe-mode
```

#### Changes Breaking Functionality

**Problem**: Applied improvements cause issues.

**Prevention**:
```bash
# Always use preview first
/sg:improve code/ --preview

# Use safe mode
/sg:improve code/ --safe-mode

# Test after changes
/sg:improve code/ --safe-mode && /test code/
```

**Recovery**:
- Use git to revert changes
- Apply improvements incrementally with `--safe-mode`
- Use `--validate` to check before applying changes

### Framework and Integration Issues üîó

#### SuperGemini Doesn't Understand Project Context

**Problem**: Recommendations don't fit your project's patterns or constraints.

**Solutions**:
```bash
# Load project context first
/sg:load --deep --summary

# Be explicit about project type
/sg:analyze react-typescript-app/ --c7  # Include tech stack in description

# Use appropriate personas
/sg:analyze node-api/ --persona-backend
/sg:analyze react-ui/ --persona-frontend
```

#### Inconsistent Results

**Problem**: Same command produces different results at different times.

**Diagnosis**:
```bash
# Check what's auto-activating differently
/sg:command args --introspect

# Use explicit flags for consistency
/sg:analyze code/ --persona-analyzer --seq --c7  # Explicit configuration
```

**Solutions**:
```bash
# Be more explicit about requirements
/sg:improve code/ --focus performance --persona-performance --safe-mode

# Use consistent flag patterns
/sg:analyze --seq --c7     # Your standard thorough analysis
/sg:improve --safe-mode      # Your standard safe improvement
```

### Getting Help üÜò

#### When You're Stuck

**Self-Diagnosis Steps**:
1. Use `--introspect` to understand what SuperGemini is thinking
2. Try simpler versions of your command
3. Check auto-activation with explicit flags
4. Use `--help` on commands to see options

**Escalation Path**:
```bash
# Get framework help
/sg:troubleshoot "SuperGemini framework issues" --introspect

# Check documentation
/sg:help                    # Command overview
/sg:analyze --help          # Specific command help

# Test basic functionality
/sg:analyze README.md       # Simple test
/sg:build --help           # Check if commands work
```

#### Reporting Issues

When reporting problems, include:
- **Exact command used**: `/analyze code/ --seq --c7`
- **Expected behavior**: "Should provide security analysis"
- **Actual behavior**: "Only provided basic code review"
- **Context**: "Working on Node.js authentication system"
- **SuperGemini version**: Check with `/help`

**Useful Debug Information**:
```bash
# Get diagnostic information
/sg:troubleshoot "describe your issue" --introspect --verbose
# ‚Üí Provides detailed context for bug reports
```

### Quick Reference for Common Problems üìã

| Problem | Quick Fix | Command |
|---------|-----------|---------|
| Too slow | Reduce scope + compression | `--scope file --uc` |
| Wrong persona | Override explicitly | `--persona-security` |
| Too much output | Use compression | `--uc` |
| Risky changes | Use safety features | `--safe-mode --preview` |
| MCP not working | Force activation or disable | `--all-mcp` or `--no-mcp` |
| Inconsistent results | Use explicit flags | `--persona-x --seq --c7` |
| Context issues | Load project context | `/load --deep` |
| Token limits | Enable compression + wave mode | `--uc --wave-mode auto` |

Remember: When in doubt, start simple and add complexity gradually. Use `--introspect` to understand what SuperGemini is thinking, and don't hesitate to override auto-activation when you need specific behavior.

---

## What's Next üîÆ

SuperGemini v3.0 is fresh out of beta, and we're honest about what that means: it works pretty well for what it does, but there are rough edges and room for improvement. Here's what you can expect as the framework evolves.

### Current Limitations (Let's Be Honest) ‚ö†Ô∏è

#### Known Issues We're Working On

**Performance Optimization**
- Some operations are slower than we'd like, especially with all MCP servers active
- Token usage could be more efficient for large-scale operations  
- Memory usage spikes on very large codebases (>1000 files)

**MCP Server Integration**
- Server connections occasionally timeout or become unresponsive
- Error handling between MCP servers could be smoother
- Some advanced MCP features are experimental and may not work reliably

**Quality Gates**
- The 8-step validation process sometimes misses edge cases
- Quality metrics could be more granular and actionable
- Integration testing validation needs improvement

**Auto-Activation Intelligence**
- Persona selection occasionally misses context clues
- Flag auto-activation can be overly aggressive for simple tasks
- Pattern recognition works well for common scenarios but struggles with edge cases

#### What We Removed (And Why)

**Hooks System (Coming Back in v4)**
- The v2 hooks system became too complex and buggy
- Caused performance issues and unpredictable behavior
- Being redesigned from scratch with better architecture
- Will return in v4 with improved reliability and simpler configuration

**Some Advanced Commands**
- Consolidated 20+ commands down to 16 essential ones
- Removed experimental commands that weren't stable enough
- Focus on making core commands excellent rather than having many mediocre ones

### Short-Term Improvements (v3.x) üîß

Our immediate focus is making v3 stable and polished:

#### Performance Optimization (v3.1)
- **MCP Connection Pooling**: Reuse connections to reduce startup overhead
- **Intelligent Caching**: Cache MCP results and analysis outcomes
- **Token Optimization**: Better compression algorithms and smarter batching
- **Resource Management**: Better memory usage for large projects

**Expected Impact**: 30-50% performance improvement for common operations.

#### MCP Server Reliability (v3.2)  
- **Connection Resilience**: Better handling of MCP server timeouts and failures
- **Graceful Degradation**: Fallback strategies when servers are unavailable
- **Health Monitoring**: Real-time monitoring of MCP server status
- **Error Recovery**: Automatic retry and recovery mechanisms

**Expected Impact**: 80% reduction in MCP-related failures and timeouts.

#### Quality Gate Enhancement (v3.3)
- **Granular Metrics**: More specific and actionable quality measurements
- **Custom Validation**: User-configurable quality checks
- **Evidence Tracking**: Better documentation of validation outcomes
- **Integration Testing**: Improved validation of system-wide changes

**Expected Impact**: Higher confidence in automated improvements and better quality metrics.

### Medium-Term Evolution (v4.0) üöÄ

The next major version will focus on intelligence and user experience:

#### Redesigned Hooks System
- **Event-Driven Architecture**: Clean separation between framework and hooks
- **Performance Optimized**: No impact on core operations when hooks aren't used
- **Simple Configuration**: Easy setup and debugging
- **Extensibility**: Community hooks and custom integrations

#### Enhanced AI Coordination
- **Smarter Auto-Activation**: Better context understanding and tool selection
- **Learning Patterns**: Framework learns from your successful workflows
- **Predictive Assistance**: Suggests next steps based on current context
- **Personalization**: Adapts to your coding style and preferences

#### Advanced Orchestration
- **Dynamic Resource Allocation**: Intelligent scaling based on operation complexity
- **Parallel Processing**: True parallelization for independent operations
- **Context Preservation**: Better memory of previous work within sessions
- **Workflow Templates**: Reusable patterns for common development scenarios

#### Extended MCP Ecosystem
- **More Servers**: Additional specialized capabilities (database, cloud, monitoring)
- **Community Servers**: Framework for community-contributed MCP servers
- **Server Marketplace**: Easy discovery and installation of new capabilities
- **Local Development**: Run MCP servers locally for better performance

### Long-Term Vision (v5.0+) üåü

Looking further ahead, we're exploring more ambitious improvements:

#### Intelligence and Automation
- **Contextual Understanding**: Deep comprehension of project goals and constraints
- **Proactive Assistance**: Suggestions based on code analysis and project patterns
- **Automated Workflows**: End-to-end automation for common development tasks
- **Code Evolution Tracking**: Understanding how your codebase changes over time

#### Team and Enterprise Features
- **Multi-Developer Coordination**: Team-aware analysis and recommendations
- **Project Memory**: Persistent understanding of project context across sessions
- **Policy Enforcement**: Automated enforcement of team coding standards
- **Analytics Dashboard**: Insights into development patterns and productivity

#### Platform Integration
- **IDE Deep Integration**: Native integration with popular development environments
- **CI/CD Pipeline Integration**: Automated quality checks and improvements in build processes
- **Cloud Development**: Integration with cloud development platforms
- **API Ecosystem**: Rich APIs for custom integrations and tooling

### How You Can Influence Development üìù

#### Feedback and Usage Patterns
We actively monitor:
- **Command usage patterns**: Which commands are most/least useful
- **Flag combinations**: What combinations work well in practice
- **Error patterns**: Common failure modes and user confusion points
- **Performance bottlenecks**: Where users experience slowdowns

#### Community Involvement
- **GitHub Issues**: Bug reports and feature requests help prioritize development
- **Usage Examples**: Real-world usage examples inform our testing and optimization
- **Documentation Feedback**: Gaps in documentation highlight areas for improvement
- **Integration Requests**: Requests for specific tool/framework integrations guide MCP development

#### Beta Testing Program
- **Early Access**: Test new features before public release
- **Feedback Loop**: Direct input on experimental features
- **Performance Testing**: Help validate optimizations across different environments
- **Use Case Validation**: Ensure new features work for real development scenarios

### Staying Updated üì°

#### How to Keep Current
```bash
# Check for updates regularly
/sg:help  # Shows current version and update availability

# Monitor development progress
# - GitHub releases: Feature announcements and changelogs
# - Documentation updates: New patterns and best practices
# - Community discussions: Tips and advanced usage patterns
```

#### Migration and Compatibility
- **Backwards Compatibility**: v3.x updates maintain command compatibility
- **Configuration Migration**: Automatic migration of settings between versions
- **Deprecation Warnings**: Advance notice of changing features
- **Migration Guides**: Step-by-step guides for major version upgrades

### Realistic Expectations üìä

#### What to Expect from Updates
- **v3.x updates**: Bug fixes, performance improvements, stability enhancements
- **Major versions**: New features, architectural improvements, expanded capabilities
- **Community contributions**: Additional MCP servers, workflow patterns, integrations

#### What Not to Expect
- **Perfect AI**: SuperGemini will continue to have limitations and edge cases
- **One-Size-Fits-All**: Different projects and teams will need different approaches
- **Zero Learning Curve**: New features will require learning and experimentation
- **Magical Solutions**: Complex problems still require human expertise and judgment

### Contributing to SuperGemini ü§ù

#### Ways to Help
- **Bug Reports**: Detailed reports help improve stability and reliability
- **Feature Requests**: Real-world needs drive development priorities
- **Documentation**: Examples, guides, and clarifications help the community
- **Community Support**: Helping other users builds a stronger ecosystem

#### What We Value Most
- **Honest Feedback**: Both positive experiences and frustrations help improve the framework
- **Real-World Usage**: How SuperGemini works (or doesn't work) in actual development workflows
- **Specific Examples**: Concrete scenarios are more valuable than abstract feature requests
- **Patience**: Remember that v3.0 is fresh out of beta - improvement takes time

### The Bottom Line üéØ

SuperGemini v3.0 is a solid foundation with room to grow. We're committed to:
- **Honest Communication**: No overpromising, clear about limitations and timelines
- **User-Driven Development**: Prioritizing features that solve real problems
- **Quality Over Features**: Making existing capabilities excellent before adding new ones
- **Community Focus**: Building a framework that serves the development community

We believe SuperGemini can become significantly more helpful for software development workflows, but it will take time, feedback, and iteration to get there. We appreciate your patience, feedback, and continued use as we improve the framework together.

**Want to stay involved?** Watch the GitHub repository, try new features when they're released, and let us know what works (and what doesn't) in your development workflows. Your real-world usage and feedback are what will make SuperGemini truly valuable for the development community.

---

## Conclusion üéâ

You've now got a comprehensive understanding of SuperGemini v3.0 - its components, capabilities, and how to use them effectively. Let's wrap up with the key takeaways that will help you get the most out of the framework.

### Key Takeaways üéØ

#### SuperGemini's Core Value
SuperGemini transforms Gemini Code from a general-purpose AI assistant into a specialized development partner through:
- **15 specialized commands** that understand development workflows
- **11 expert personas** that bring domain-specific knowledge
- **Intelligent orchestration** that coordinates tools automatically
- **Quality-first approach** that maintains safety and reliability

#### The Power is in the Coordination
SuperGemini's power comes not from any single feature, but from how components work together:
- Commands usually activate appropriate personas and MCP servers
- Personas coordinate with each other for multi-domain problems
- The orchestrator optimizes tool selection and resource usage
- Quality gates ensure consistent, reliable outcomes

#### Start Simple, Scale Intelligently
The best approach to SuperGemini is progressive:
1. **Begin with basic commands** to understand core functionality
2. **Trust auto-activation** to learn optimal tool combinations
3. **Add manual control** when you need specific perspectives
4. **Experiment with advanced features** as your confidence grows

### What Makes SuperGemini Different üåü

#### Honest About Limitations
- We acknowledge v3.0 is fresh out of beta with rough edges
- We clearly document what works well vs. what's still experimental
- We prioritize reliability over flashy features
- We provide realistic timelines and expectations

#### Evidence-Based Development
- All recommendations backed by verifiable data
- Quality gates ensure changes don't break existing functionality
- Performance optimizations based on real usage patterns
- Continuous improvement driven by user feedback

#### Respectful of Your Workflow
- Enhances existing tools rather than replacing them
- Maintains compatibility with standard development practices
- Provides manual override for all automatic decisions
- Scales from simple tasks to complex enterprise scenarios

### Practical Next Steps üõ£Ô∏è

#### For New Users
1. **Start with installation**: Follow the [Installation Guide](installation-guide.md)
2. **Try basic commands**: `/help`, `/analyze README.md`, `/build --help`
3. **Explore domain guides**: [Commands](commands-guide.md), [Flags](flags-guide.md), [Personas](personas-guide.md)
4. **Build confidence gradually**: Simple tasks ‚Üí complex workflows ‚Üí advanced features

#### For Experienced Users
1. **Optimize your workflows**: Identify flag combinations that work well for your needs
2. **Experiment with coordination**: Try different persona combinations on complex problems
3. **Contribute feedback**: Share what works (and what doesn't) in your environment
4. **Explore advanced features**: Wave orchestration, sub-agent delegation, introspection mode

### When to Use SuperGemini ü§î

#### SuperGemini Excels At
- **Development workflows**: Building, testing, deploying, documenting
- **Code analysis**: Quality assessment, security scanning, performance optimization
- **Learning and understanding**: Explaining complex systems, onboarding to new projects
- **Quality improvement**: Systematic refactoring, technical debt reduction
- **Multi-domain problems**: Issues requiring multiple types of expertise

#### When to Use Standard Gemini Code
- **Simple questions**: Quick explanations that don't need specialized tools
- **Creative writing**: Non-technical content creation
- **General research**: Topics outside software development
- **Brainstorming**: Open-ended ideation without specific implementation needs

### The SuperGemini Philosophy üí≠

#### Human-AI Collaboration
SuperGemini is designed to augment human expertise, not replace it:
- **You provide context and goals** - SuperGemini provides execution and expertise
- **You make decisions** - SuperGemini provides evidence and recommendations  
- **You understand your constraints** - SuperGemini respects and works within them
- **You own the outcomes** - SuperGemini helps you achieve better results

#### Continuous Improvement
The framework gets better through:
- **Usage patterns**: Learning what combinations work well in practice
- **User feedback**: Real-world experiences drive development priorities
- **Evidence-based optimization**: Data-driven improvements to tools and workflows
- **Community contributions**: Shared knowledge and best practices

### Looking Forward üîÆ

#### Short-Term (Next 6 Months)
- Performance optimizations making operations 30-50% faster
- Improved MCP server reliability reducing failures by 80%
- Enhanced quality gates providing more actionable feedback
- Better documentation based on user questions and feedback

#### Medium-Term (6-18 Months)  
- Redesigned hooks system with better architecture and performance
- Smarter auto-activation based on learning from usage patterns
- Extended MCP ecosystem with community-contributed servers
- Advanced orchestration with true parallel processing

#### Long-Term Vision
- Deep contextual understanding of projects and team workflows
- Proactive assistance based on code analysis and project patterns
- Team-aware features for collaborative development
- Rich integration ecosystem with IDEs, CI/CD, and cloud platforms

### Final Thoughts üéâ

SuperGemini v3.0 represents a solid foundation for enhanced software development workflows. While it's not perfect and still has room for improvement, it demonstrates how AI can be thoughtfully integrated into development practices without disrupting existing workflows or replacing human expertise.

The framework succeeds when it makes you more productive, helps you learn new things, or catches issues you might have missed. It's designed to be a helpful colleague rather than a replacement for understanding your craft.

#### Thank You üôè

Thanks for taking the time to understand SuperGemini thoroughly. Your thoughtful usage, honest feedback, and patience with rough edges are what will make this framework truly valuable for the development community.

Whether you use SuperGemini occasionally for specific tasks or integrate it deeply into your daily workflow, we hope it makes your development experience a bit better. And when it doesn't work as expected, please let us know - that feedback is invaluable for making improvements.

**Happy coding!** üöÄ We're excited to see what you build with SuperGemini as your development partner.

---

*Last updated: July 2024*  
*SuperGemini v3.0 User Guide*

*For questions, feedback, or contributions, visit our GitHub repository or join the community discussions. We're always happy to hear from users and learn about your experiences with the framework.*
